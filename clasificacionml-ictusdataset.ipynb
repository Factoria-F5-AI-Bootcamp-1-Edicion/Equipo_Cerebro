{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib \nplt.style.use(\"ggplot\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocesado y modelado\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_sample_weight\nfrom imblearn.under_sampling import RandomUnderSampler \nfrom sklearn.model_selection import train_test_split\n# Configuración warnings\nimport warnings\nwarnings.filterwarnings('once')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Algoritmos de ensemble\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import VotingClassifier\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nimport lightgbm \nimport catboost\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Optimización de hiperparámetros\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import ParameterGrid\nimport multiprocessing\nfrom multiprocessing import Pool\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.model_selection import KFold","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Métricas de evaluación\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import make_scorer","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df= pd.read_csv('/kaggle/input/ictus-data-set/stroke_dataset.csv')\ndf.head(5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in  range(len(df)):\n    if df[\"gender\"][i]=='Male':\n        df[\"gender\"][i]='0'\n    else :\n        df[\"gender\"][i]='1'\n\ndf[[ \"gender\" ]] = df[[ \"gender\" ]].astype(int)\ndf.gender.value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in  range(len(df)):\n    if df[\"Residence_type\"][i]=='Rural':\n        df[\"Residence_type\"][i]='0'\n    else :\n        df[\"Residence_type\"][i]='1'\n        \ndf[[ \"Residence_type\" ]] = df[[ \"Residence_type\" ]].astype(int)\ndf.Residence_type.value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in  range(len(df)):\n    if df[\"ever_married\"][i]=='No':\n        df[\"ever_married\"][i]='0'\n    else :\n        df[\"ever_married\"][i]='1'\n        \ndf[[ \"ever_married\" ]] = df[[ \"ever_married\" ]].astype(int)\ndf.ever_married.value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[[ \"stroke\" ]] = df[[ \"stroke\" ]].astype(int)\ndf.stroke.value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[[ \"hypertension\", \"heart_disease\" ]] = df[[ \"hypertension\", \"heart_disease\" ]].astype('bool').astype(int)\ndf.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['age']= df['age'].round()\ndf[[\"age\"]]= df[[\"age\"]].astype(int)\ndf.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler, OneHotEncoder , LabelEncoder\nfrom sklearn.compose import ColumnTransformer\n\nnumericas = [\"age\", \"avg_glucose_level\" , \"bmi\" , \"hypertension\", \"heart_disease\"]\ncategoricas= [\"work_type\" , \"smoking_status\" , \"gender\", \"ever_married\" , \"Residence_type\"]\n\n#Configuro los transformer\ntransformer_numerico = (\"transformer_numerico\",MinMaxScaler(), numericas) \ntransformer_categorico = (\"transformer_categorico\",OneHotEncoder(), categoricas)\n\n#Defino el transformer\ntransformer = ColumnTransformer ([transformer_numerico, transformer_categorico ], remainder=\"passthrough\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.drop('stroke',axis=1)\ny= df['stroke']\nX_ub = transformer.fit_transform(X) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler  \nfrom sklearn.model_selection import train_test_split\n\nrus = RandomUnderSampler(sampling_strategy=1) # Float \nX_rus, y_rus = rus.fit_resample(X,y)  \nX_rus = transformer.fit_transform(X_rus) \nX_train_rus, X_test_rus, y_train_rus, y_test_rus = train_test_split(X_rus, y_rus, test_size=0.20, random_state=101, stratify=y_rus)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Algoritmos ensemble con balanceo de datos ---->> RandomUnderSampler","metadata":{}},{"cell_type":"markdown","source":"# RamdomForestClassifier -----> Grid Search basado en validación cruzada","metadata":{}},{"cell_type":"code","source":"# Grid de hiperparámetros evaluados RandomForestClassifier\n# ==============================================================================\nparam_grid = {'n_estimators'  : [50, 100, 500, 1000],\n              'criterion'     : ['gini', 'entropy', 'log_loss'],\n              'max_features'  : ['auto', 'sqrt', 'log2'],\n              #'max_depth'     : [None, 1, 3, 5, 10, 20]\n             }\n\n# Búsqueda por grid search con validación cruzada RandomForetsClassifier\n# ==============================================================================\ngrid_RFC = GridSearchCV(\n        estimator  = RandomForestClassifier(random_state=123),\n        param_grid = param_grid,\n        scoring    = 'accuracy',\n        n_jobs     = multiprocessing.cpu_count() - 1,\n        cv         = RepeatedKFold(n_splits=3, n_repeats=1, random_state=123), \n        refit      = True,\n        verbose    = 0,\n        return_train_score = True\n       )\n\ngrid_RFC.fit(X = X_train_bal, y = y_train_bal)\n\n# Resultados RandomForetsClassifier\n# ==============================================================================\nprint(\"Resultados GridSearch ---->>> RandomForestClassifier\")\nprint()\nresultados = pd.DataFrame(grid_RFC.cv_results_)\nresultados.filter(regex = '(param*|mean_t|std_t)') \\\n    .drop(columns = 'params') \\\n    .sort_values('mean_test_score', ascending = False) \\\n    .head(4)\n\n# Mejores hiperparámetros por validación cruzada RandomForestClassifier\n# ==============================================================================\nprint(\"----------------------------------------\")\nprint(\"Mejores hiperparámetros encontrados (cv) RandomForestClassifier\")\nprint(\"----------------------------------------\")\nprint(grid_RFC.best_params_, \":\", grid_RFC.best_score_, grid_RFC.scoring)\n\n# RFC con optimización de hiperparámetros\nmodelo_RFC_bal = grid_RFC.best_estimator_\n#Accuracy del modelo\nRFC_accuracy = grid_RFC.best_score_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cross Validation\ncv_RFC_bal = cross_validate(modelo_RFC_bal, X_bal, y_bal, cv=10)\nsorted(cv_RFC_bal.keys())\ncv_RFC_bal['test_score']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accuracy cross_validatation\ncv_RFC_mean_bal =sum(cv_RFC_bal['test_score'])/len(cv_RFC_bal['test_score'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Prediccion y evaluacion del modelo\ny_pred_bal= modelo_RFC_bal.predict(X_test_bal)\ny_pred_train_bal= modelo_RFC_bal.predict(X_train_bal)\n\n#Accuracy del modelo\naccuracy_test_predict= accuracy_score(y_test_bal, y_pred_bal)\n#Accuracy del train\naccuracy_train_bal = accuracy_score(y_train_bal,y_pred_train_bal)\n\nprint(\"\")\nprint(\"El accuracy de test es: {:.2f} %\".format(100 * accuracy_test_predict))\nprint(\"\")\nprint(\"El accuracy del train es: {:.2f} %\".format(100 * accuracy_train_bal))\nprint(\"\")\nprint(\"El overfitting del test y train es {:.2f} % \".format(((accuracy_test_predict - accuracy_train_bal)/accuracy_test_predict) *100))\nprint(\"\")\nprint(\"El accuracy del cross_validate es: {:.2f} %\".format(100 * cv_RFC_mean_bal))\nprint(\"\")\nprint(\"El overfitting del cross_validate (test) y train es {:.2f} % \".format(((cv_RFC_mean_bal - accuracy_train_bal)/accuracy_test_predict) *100))\nprint(\"\")\nprint(\"\")\n\n#definimos funciona para mostrar los resultados\nprint(\"Matriz de confusión\")\nprint(\"\")\n\nLabels= 'No_Stroke', 'Stroke'\n\ndef mostrar_resultados(y_test_bal, y_pred_bal):\n    conf_matrix = confusion_matrix(y_test_bal, y_pred_bal)\n    plt.figure(figsize=(8, 8))\n    sns.heatmap(conf_matrix, xticklabels=Labels, yticklabels=Labels, annot=True, fmt=\"d\");\n    plt.title(\"Matriz de confusión\")\n    plt.ylabel('True class')\n    plt.xlabel('Predicted class')\n    plt.show()\n    print(\"\")\n    print(\"Reporte de Clasificación (test)\")\n    print(\"-------------------\")\n    print (classification_report(y_test_bal, y_pred_bal))\n    \nmostrar_resultados(y_test_bal, y_pred_bal)\nprint(\"\")\nprint(\"Reporte de Clasificación (train)\")\nprint(\"-------------------\")\nprint (classification_report(y_train_bal,y_pred_train_bal))\nprint(\"\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Accuracy de las predicciones sobre test\naccuracy_test_predict= accuracy_score(y_test_bal, y_pred_bal)\n#Accuracy de las predicciones sobre train (para overfitting)\naccuracy_train_bal= accuracy_score(y_train_bal, y_pred_train_bal)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# AdaBoostClassifier -----> Grid Search basado en validación cruzada","metadata":{}},{"cell_type":"code","source":"# Grid de hiperparámetros evaluados\n# ==============================================================================\nparam_grid = {'n_estimators'  : [50, 100, 500, 1000],\n              'algorithm'     : ['SAMME', 'SAMME.R'],\n              'learning_rate' : [0.001, 0.01, 0.1]\n             }\n\n# Búsqueda por grid search con validación cruzada\n# ==============================================================================\ngrid_ADBC = GridSearchCV(\n        estimator  = AdaBoostClassifier (random_state=123),\n        param_grid = param_grid,\n        scoring    = 'accuracy',\n        n_jobs     = multiprocessing.cpu_count() - 1,\n        cv         = RepeatedKFold(n_splits=3, n_repeats=1, random_state=123), \n        refit      = True,\n        verbose    = 0,\n        return_train_score = True\n       )\n\n#ahora hacemos el entrenamiento del modelo\ngrid_ADBC.fit(X = X_train_bal, y = y_train_bal)\n\n# Resultados\n# ==============================================================================\nprint(\"Resultados GridSearch ---->>> AdaBoostClassifier\")\nresultados = pd.DataFrame(grid_ADBC.cv_results_)\nresultados.filter(regex = '(param*|mean_t|std_t)') \\\n    .drop(columns = 'params') \\\n    .sort_values('mean_test_score', ascending = False) \\\n    .head(4)\n\n# Mejores hiperparámetros por validación cruzada AdaBoostClassifier\n# ==============================================================================\nprint(\"----------------------------------------\")\nprint(\"Mejores hiperparámetros encontrados (cv) AdaBoostClassifier\")\nprint(\"----------------------------------------\")\nprint(grid_ADBC.best_params_, \":\", grid_ADBC.best_score_, grid_ADBC.scoring)\n\n#Guardamos el mejor modelo y su accuracy\nmodelo_ADBC_bal = grid_ADBC.best_estimator_\n#Accuracy del modelo\nRFC_accuracy = grid_RFC.best_score_\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cross validation\ncv_ADBC_bal = cross_validate(modelo_ADBC_bal, X_bal, y_bal, cv=10)\nsorted(cv_ADBC_bal.keys())\ncv_ADBC_bal['test_score']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accuracy cross_validation\ncv_ADBC_mean_bal =sum(cv_ADBC_bal['test_score'])/len(cv_ADBC_bal['test_score'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prediccion y evaluacion del modelo\ny_pred_bal= modelo_ADBC_bal.predict(X_test_bal)\ny_pred_train_bal= modelo_ADBC_bal.predict(X_train_bal)\n\n#Accuracy del modelo\naccuracy_test_predict= accuracy_score(y_test_bal, y_pred_bal)\n#Accuracy del train\naccuracy_train_bal = accuracy_score(y_train_bal,y_pred_train_bal)\n\nprint(\"\")\nprint(\"El accuracy de test es: {:.2f} %\".format(100 * accuracy_test_predict))\nprint(\"\")\nprint(\"El accuracy del train es: {:.2f} %\".format(100 * accuracy_train_bal))\nprint(\"\")\nprint(\"El overfitting del test y train es {:.2f} % \".format(((accuracy_test_predict - accuracy_train_bal)/accuracy_test_predict) *100))\nprint(\"\")\nprint(\"El accuracy del cross_validate es: {:.2f} %\".format(100 * cv_ADBC_mean_bal))\nprint(\"\")\nprint(\"El overfitting del cross_validate (test) y train es {:.2f} % \".format(((cv_ADBC_mean_bal - accuracy_train_bal)/accuracy_test_predict) *100))\nprint(\"\")\nprint(\"\")\n\n#definimos funciona para mostrar los resultados\nprint(\"Matriz de confusión\")\nprint(\"\")\n\nLabels= 'No_Stroke', 'Stroke'\n\ndef mostrar_resultados(y_test_bal, y_pred_bal):\n    conf_matrix = confusion_matrix(y_test_bal, y_pred_bal)\n    plt.figure(figsize=(8, 8))\n    sns.heatmap(conf_matrix, xticklabels=Labels, yticklabels=Labels, annot=True, fmt=\"d\");\n    plt.title(\"Matriz de confusión\")\n    plt.ylabel('True class')\n    plt.xlabel('Predicted class')\n    plt.show()\n    print(\"\")\n    print(\"Reporte de Clasificación (test)\")\n    print(\"-------------------\")\n    print (classification_report(y_test_bal, y_pred_bal))\n    \nmostrar_resultados(y_test_bal, y_pred_bal)\nprint(\"\")\nprint(\"Reporte de Clasificación (train)\")\nprint(\"-------------------\")\nprint (classification_report(y_train_bal,y_pred_train_bal))\nprint(\"\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBoostClassifier -----> Grid Search basado en validación cruzada","metadata":{}},{"cell_type":"code","source":"# Grid de hiperparámetros evaluados XGBoostClassifier\n# ==============================================================================\nparam_grid = {'n_estimators'  : [50, 100, 500, 1000],\n              'max_depth'     : [None, 1, 3, 5, 10, 20],\n              'subsample'     : [0.5, 1],\n              'learning_rate' : [0.001, 0.01, 0.1]\n             }\n\n# Búsqueda por grid search con validación cruzada XGBoostClassifier\n# ==============================================================================\ngrid_XGBC = GridSearchCV(\n        estimator  = XGBClassifier(random_state=123),\n        param_grid = param_grid,\n        scoring    = 'accuracy',\n        n_jobs     = multiprocessing.cpu_count() - 1,\n        cv         = RepeatedKFold(n_splits=3, n_repeats=1, random_state=123), \n        refit      = True,\n        verbose    = 0,\n        return_train_score = True\n       )\n\ngrid_XGBC.fit(X = X_train_bal, y = y_train_bal)\n\n# Resultados XGBoostClassifier\n# ==============================================================================\nprint(\"Resultados GridSearch ---->>> XGBClassifier\")\nprint()\nresultados = pd.DataFrame(grid_XGBC.cv_results_)\nresultados.filter(regex = '(param*|mean_t|std_t)') \\\n    .drop(columns = 'params') \\\n    .sort_values('mean_test_score', ascending = False) \\\n    .head(4)\n\n# Mejores hiperparámetros por validación cruzada XGBClassifier\n# ==============================================================================\nprint(\"----------------------------------------\")\nprint(\"Mejores hiperparámetros encontrados (cv) XGBClassifier\")\nprint(\"----------------------------------------\")\nprint(grid_XGBC.best_params_, \":\", grid_XGBC.best_score_, grid_XGBC.scoring)\n\n# Guardamos el mejor modelo y el accuracy\nmodelo_XGBC_bal = grid_XGBC.best_estimator_\n#Accuracy del modelo\nRFC_accuracy = grid_RFC.best_score_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cross Validation\ncv_XGBC_bal = cross_validate(modelo_XGBC_bal, X_bal, y_bal, cv=10)\nsorted(cv_XGBC_bal.keys())\ncv_XGBC_bal['test_score']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accuracy cross_validation\ncv_XGBC_mean_bal =sum(cv_XGBC_bal['test_score'])/len(cv_XGBC_bal['test_score'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicciones y evaluación del modelo (overfitting)\ny_pred_bal= modelo_XGBC_bal.predict(X_test_bal)\ny_pred_train_bal= modelo_XGBC_bal.predict(X_train_bal)\n\n#Accuracy del modelo\naccuracy_test_predict= accuracy_score(y_test_bal, y_pred_bal)\n#Accuracy del train\naccuracy_train_bal = accuracy_score(y_train_bal,y_pred_train_bal)\n\nprint(\"\")\nprint(\"El accuracy de test es: {:.2f} %\".format(100 * accuracy_test_predict))\nprint(\"\")\nprint(\"El accuracy del train es: {:.2f} %\".format(100 * accuracy_train_bal))\nprint(\"\")\nprint(\"El overfitting del test y train es {:.2f} % \".format(((accuracy_test_predict - accuracy_train_bal)/accuracy_test_predict) *100))\nprint(\"\")\nprint(\"El accuracy del cross_validate es: {:.2f} %\".format(100 * cv_XGBC_mean_bal))\nprint(\"\")\nprint(\"El overfitting del cross_validate (test) y train es {:.2f} % \".format(((cv_XGBC_mean_bal - accuracy_train_bal)/accuracy_test_predict) *100))\nprint(\"\")\nprint(\"\")\n\n#definimos funciona para mostrar los resultados\nprint(\"Matriz de confusión\")\nprint(\"\")\n\nLabels= 'No_Stroke', 'Stroke'\n\ndef mostrar_resultados(y_test_bal, y_pred_bal):\n    conf_matrix = confusion_matrix(y_test_bal, y_pred_bal)\n    plt.figure(figsize=(8, 8))\n    sns.heatmap(conf_matrix, xticklabels=Labels, yticklabels=Labels, annot=True, fmt=\"d\");\n    plt.title(\"Matriz de confusión\")\n    plt.ylabel('True class')\n    plt.xlabel('Predicted class')\n    plt.show()\n    print(\"\")\n    print(\"Reporte de Clasificación (test)\")\n    print(\"-------------------\")\n    print (classification_report(y_test_bal, y_pred_bal))\n    \nmostrar_resultados(y_test_bal, y_pred_bal)\nprint(\"\")\nprint(\"Reporte de Clasificación (train)\")\nprint(\"-------------------\")\nprint (classification_report(y_train_bal,y_pred_train_bal))\nprint(\"\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LGBMClassifier","metadata":{}},{"cell_type":"code","source":"# Grid de hiperparámetros evaluados\n# ==============================================================================\nparam_grid = {\n    'learning_rate': [0.005, 0.01],\n    'n_estimators': [8,16,24],\n    'num_leaves': [6,8,12,16], # large num_leaves helps improve accuracy but might lead to over-fitting\n    'boosting_type' : ['gbdt', 'dart'], # for better accuracy -> try dart\n    'objective' : ['binary'],\n    'max_bin':[255, 510], # large max_bin helps improve accuracy but might slow down training progress\n    'colsample_bytree' : [0.64, 0.65, 0.66],\n    'subsample' : [0.7,0.75],\n    'reg_alpha' : [1,1.2],\n    'reg_lambda' : [1,1.2,1.4],\n    }\n\n# Búsqueda por grid search con validación cruzada\n# ==============================================================================\ngrid_LGBMC = GridSearchCV(\n        estimator  = LGBMClassifier (random_state=123),\n        param_grid = param_grid,\n        scoring    = 'accuracy',\n        n_jobs     = multiprocessing.cpu_count() - 1,\n        cv         = RepeatedKFold(n_splits=3, n_repeats=1, random_state=123), \n        refit      = True,\n        verbose    = 0,\n        return_train_score = True\n       )\n\n#ahora hacemos el entrenamiento del modelo\ngrid_LGBMC.fit(X = X_train_bal, y = y_train_bal)\n\n# Resultados\n# ==============================================================================\nprint(\"Resultados GridSearch ---->>> LGBMClassifier\")\nresultados = pd.DataFrame(grid_LGBMC.cv_results_)\nresultados.filter(regex = '(param*|mean_t|std_t)') \\\n    .drop(columns = 'params') \\\n    .sort_values('mean_test_score', ascending = False) \\\n    .head(4)\n\n# Mejores hiperparámetros por validación cruzada LGBMClassifier\n# ==============================================================================\nprint(\"----------------------------------------\")\nprint(\"Mejores hiperparámetros encontrados (cv) LGBMClassifier\")\nprint(\"----------------------------------------\")\nprint(grid_LGBMC.best_params_, \":\", grid_LGBMC.best_score_, grid_LGBMC.scoring)\n\n# Guardamos el mejor modelo y el accuracy\nmodelo_LGBMC_bal = grid_LGBMC.best_estimator_\n# Accuracy del modelo\nLGBMC_accuracy = grid_LGBMC.best_score_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cross_validation\ncv_LGBMC_bal = cross_validate(modelo_LGBMC_bal, X_bal, y_bal, cv=10)\nsorted(cv_LGBMC_bal.keys())\ncv_LGBMC_bal['test_score']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accuracy cross_validation\ncv_LGBMC_mean_bal =sum(cv_LGBMC_bal['test_score'])/len(cv_LGBMC_bal['test_score'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prediccion y evaluacion del modelo\ny_pred_bal= modelo_LGBMC_bal.predict(X_test_bal)\ny_pred_train_bal= modelo_LGBMC_bal.predict(X_train_bal)\n\n#Accuracy del modelo\naccuracy_test_predict= accuracy_score(y_test_bal, y_pred_bal)\n#Accuracy del train\naccuracy_train_bal = accuracy_score(y_train_bal,y_pred_train_bal)\n\nprint(\"\")\nprint(\"El accuracy de test es: {:.2f} %\".format(100 * accuracy_test_predict))\nprint(\"\")\nprint(\"El accuracy del train es: {:.2f} %\".format(100 * accuracy_train_bal))\nprint(\"\")\nprint(\"El overfitting del test y train es {:.2f} % \".format(((accuracy_test_predict - accuracy_train_bal)/accuracy_test_predict) *100))\nprint(\"\")\nprint(\"El accuracy del cross_validate es: {:.2f} %\".format(100 * cv_LGBMC_mean_bal))\nprint(\"\")\nprint(\"El overfitting del cross_validate (test) y train es {:.2f} % \".format(((cv_LGBMC_mean_bal - accuracy_train_bal)/accuracy_test_predict) *100))\nprint(\"\")\nprint(\"\")\n\n#definimos funciona para mostrar los resultados\nprint(\"Matriz de confusión\")\nprint(\"\")\n\nLabels= 'No_Stroke', 'Stroke'\n\ndef mostrar_resultados(y_test_bal, y_pred_bal):\n    conf_matrix = confusion_matrix(y_test_bal, y_pred_bal)\n    plt.figure(figsize=(8, 8))\n    sns.heatmap(conf_matrix, xticklabels=Labels, yticklabels=Labels, annot=True, fmt=\"d\");\n    plt.title(\"Matriz de confusión\")\n    plt.ylabel('True class')\n    plt.xlabel('Predicted class')\n    plt.show()\n    print(\"\")\n    print(\"Reporte de Clasificación (test)\")\n    print(\"-------------------\")\n    print (classification_report(y_test_bal, y_pred_bal))\n    \nmostrar_resultados(y_test_bal, y_pred_bal)\nprint(\"\")\nprint(\"Reporte de Clasificación (train)\")\nprint(\"-------------------\")\nprint (classification_report(y_train_bal,y_pred_train_bal))\nprint(\"\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CatBoostClassifier -----> Grid Search basado en validación cruzada","metadata":{}},{"cell_type":"code","source":"# Grid de hiperparámetros evaluados\n# ==============================================================================\nparam_grid = {'depth'         : [4,5,6,7,8,9, 10],\n              'learning_rate' : [0.01,0.02,0.03,0.04],\n              'iterations'    : [10, 20,30,40,50,60,70,80,90, 100]\n             }\n\n# Búsqueda por grid search con validación cruzada\n# ==============================================================================\ngrid_CBC = GridSearchCV(\n        estimator  = CatBoostClassifier(random_state=123),\n        param_grid = param_grid,\n        scoring    = 'accuracy',\n        n_jobs     = multiprocessing.cpu_count() - 1,\n        cv         = RepeatedKFold(n_splits=3, n_repeats=1, random_state=123), \n        refit      = True,\n        verbose    = 0,\n        return_train_score = True\n       )\n\ngrid_CBC.fit(X = X_train_bal, y = y_train_bal)\n\n# Resultados\n# ==============================================================================\nprint(\"Resultados GridSearch ---->>> CatBoostClassifier\")\nresultados = pd.DataFrame(grid_CBC.cv_results_)\nresultados.filter(regex = '(param*|mean_t|std_t)') \\\n    .drop(columns = 'params') \\\n    .sort_values('mean_test_score', ascending = False) \\\n    .head(4)\n\n# Mejores hiperparámetros por validación cruzada CatBoostClassifier\n# ==============================================================================\nprint(\"----------------------------------------\")\nprint(\"Mejores hiperparámetros encontrados (cv) CatBoostClassifier\")\nprint(\"----------------------------------------\")\nprint(grid_CBC.best_params_, \":\", grid_CBC.best_score_, grid_CBC.scoring)\n\n# Mejores hiperparámetros por validación cruzada CatBoostClassifier\n# ==============================================================================\nprint(\"----------------------------------------\")\nprint(\"Mejores hiperparámetros encontrados (cv) CatBoostClassifier\")\nprint(\"----------------------------------------\")\nprint(grid_CBC.best_params_, \":\", grid_CBC.best_score_, grid_CBC.scoring)\n\n# Guardar el mejor modelo y el accuracy\nmodelo_CBC_bal = grid_CBC.best_estimator_\n#Accuracy del modelo\nRFC_accuracy = grid_RFC.best_score_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cross_validate CatBoostClassifier\ncv_CBC_bal = cross_validate(modelo_CBC_bal, X_bal, y_bal, cv=10)\nsorted(cv_CBC_bal.keys())\ncv_CBC_bal['test_score']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accuracy cross_validate)\ncv_CBC_mean_bal =sum(cv_CBC_bal['test_score'])/len(cv_CBC_bal['test_score'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prediccion y evaluacion del modelo CatBoostClassifier\ny_pred_bal= modelo_CBC_bal.predict(X_test_bal)\ny_pred_train_bal= modelo_CBC_bal.predict(X_train_bal)\n\n#Accuracy del modelo\naccuracy_test_predict= accuracy_score(y_test_bal, y_pred_bal)\n#Accuracy del train\naccuracy_train_bal = accuracy_score(y_train_bal,y_pred_train_bal)\n\nprint(\"\")\nprint(\"El accuracy de test es: {:.2f} %\".format(100 * accuracy_test_predict))\nprint(\"\")\nprint(\"El accuracy del train es: {:.2f} %\".format(100 * accuracy_train_bal))\nprint(\"\")\nprint(\"El overfitting del test y train es {:.2f} % \".format(((accuracy_test_predict - accuracy_train_bal)/accuracy_test_predict) *100))\nprint(\"\")\nprint(\"El accuracy del cross_validate es: {:.2f} %\".format(100 * cv_CBC_mean_bal))\nprint(\"\")\nprint(\"El overfitting del cross_validate (test) y train es {:.2f} % \".format(((cv_CBC_mean_bal - accuracy_train_bal)/accuracy_test_predict) *100))\nprint(\"\")\nprint(\"\")\n\n#definimos funciona para mostrar los resultados\nprint(\"Matriz de confusión\")\nprint(\"\")\n\nLabels= 'No_Stroke', 'Stroke'\n\ndef mostrar_resultados(y_test_bal, y_pred_bal):\n    conf_matrix = confusion_matrix(y_test_bal, y_pred_bal)\n    plt.figure(figsize=(8, 8))\n    sns.heatmap(conf_matrix, xticklabels=Labels, yticklabels=Labels, annot=True, fmt=\"d\");\n    plt.title(\"Matriz de confusión\")\n    plt.ylabel('True class')\n    plt.xlabel('Predicted class')\n    plt.show()\n    print(\"\")\n    print(\"Reporte de Clasificación (test)\")\n    print(\"-------------------\")\n    print (classification_report(y_test_bal, y_pred_bal))\n    \nmostrar_resultados(y_test_bal, y_pred_bal)\nprint(\"\")\nprint(\"Reporte de Clasificación (train)\")\nprint(\"-------------------\")\nprint (classification_report(y_train_bal,y_pred_train_bal))\nprint(\"\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}